{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3f45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80bda8c",
   "metadata": {},
   "source": [
    "# Question 1: Spark version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f1765a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f21ce",
   "metadata": {},
   "source": [
    "# Upload fhv data for homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9974a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc22ed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-06 08:40:51--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240306T084052Z&X-Amz-Expires=300&X-Amz-Signature=3d56c842d2814bb3438e9eeb4d0809f31bff02eee005747953edee1319b6cb10&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-06 08:40:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240306T084052Z&X-Amz-Expires=300&X-Amz-Signature=3d56c842d2814bb3438e9eeb4d0809f31bff02eee005747953edee1319b6cb10&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-03-06 08:40:52 (194 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142350ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 19M\r\n",
      "-rw-rw-r-- 1 alex alex  19M Dec  2  2022 fhv_tripdata_2019-10.csv.gz\r\n",
      "-rw-rw-r-- 1 alex alex  10K Mar  6 08:40 homework_note.ipynb\r\n",
      "-rw-rw-r-- 1 alex alex  13K Aug 17  2016 taxi+_zone_lookup.csv\r\n",
      "-rw-rw-r-- 1 alex alex 5.5K Mar  4 18:04 test_spark.ipynb\r\n",
      "drwxr-xr-x 2 alex alex 4.0K Mar  4 14:46 zones\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8a9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -dk fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd72e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 133M\r\n",
      "-rw-rw-r-- 1 alex alex 115M Dec  2  2022 fhv_tripdata_2019-10.csv\r\n",
      "-rw-rw-r-- 1 alex alex  19M Dec  2  2022 fhv_tripdata_2019-10.csv.gz\r\n",
      "-rw-rw-r-- 1 alex alex  10K Mar  6 08:40 homework_note.ipynb\r\n",
      "-rw-rw-r-- 1 alex alex  13K Aug 17  2016 taxi+_zone_lookup.csv\r\n",
      "-rw-rw-r-- 1 alex alex 5.5K Mar  4 18:04 test_spark.ipynb\r\n",
      "drwxr-xr-x 2 alex alex 4.0K Mar  4 14:46 zones\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f40374",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00f537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897494 fhv_tripdata_2019-10.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189bec6",
   "metadata": {},
   "source": [
    "# Start spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4323afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/06 08:41:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bcdb7",
   "metadata": {},
   "source": [
    "# Upload fhv data to spark and check schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab2d90ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf2ecacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998f117c",
   "metadata": {},
   "source": [
    "# Take a small part of fhv data to check types and create a schema for spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc3bf87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 101 fhv_tripdata_2019-10.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ddb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2734c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de48a779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2019-10-01 00:23:00</td>\n",
       "      <td>2019-10-01 00:35:00</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2019-10-01 00:11:29</td>\n",
       "      <td>2019-10-01 00:13:22</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:11:43</td>\n",
       "      <td>2019-10-01 00:37:20</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:56:29</td>\n",
       "      <td>2019-10-01 00:57:47</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:23:09</td>\n",
       "      <td>2019-10-01 00:28:27</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:06:02</td>\n",
       "      <td>2019-10-01 00:14:04</td>\n",
       "      <td>264</td>\n",
       "      <td>242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:03:43</td>\n",
       "      <td>2019-10-01 00:07:26</td>\n",
       "      <td>264</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B02534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:37:14</td>\n",
       "      <td>2019-10-01 00:51:58</td>\n",
       "      <td>264</td>\n",
       "      <td>241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B02879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:42:41</td>\n",
       "      <td>2019-10-01 00:54:42</td>\n",
       "      <td>264</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B02875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B00310</td>\n",
       "      <td>2019-10-01 00:15:57</td>\n",
       "      <td>2019-10-01 00:18:27</td>\n",
       "      <td>264</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B02879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0                B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
       "1                B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
       "2                B00014  2019-10-01 00:11:43  2019-10-01 00:37:20   \n",
       "3                B00014  2019-10-01 00:56:29  2019-10-01 00:57:47   \n",
       "4                B00014  2019-10-01 00:23:09  2019-10-01 00:28:27   \n",
       "..                  ...                  ...                  ...   \n",
       "95               B00310  2019-10-01 00:06:02  2019-10-01 00:14:04   \n",
       "96               B00310  2019-10-01 00:03:43  2019-10-01 00:07:26   \n",
       "97               B00310  2019-10-01 00:37:14  2019-10-01 00:51:58   \n",
       "98               B00310  2019-10-01 00:42:41  2019-10-01 00:54:42   \n",
       "99               B00310  2019-10-01 00:15:57  2019-10-01 00:18:27   \n",
       "\n",
       "    PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0            264           264      NaN                 B00009  \n",
       "1            264           264      NaN                 B00013  \n",
       "2            264           264      NaN                 B00014  \n",
       "3            264           264      NaN                 B00014  \n",
       "4            264           264      NaN                 B00014  \n",
       "..           ...           ...      ...                    ...  \n",
       "95           264           242      NaN                 B00310  \n",
       "96           264           213      NaN                 B02534  \n",
       "97           264           241      NaN                 B02879  \n",
       "98           264           213      NaN                 B02875  \n",
       "99           264           147      NaN                 B02879  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a61aba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num       object\n",
       "pickup_datetime            object\n",
       "dropOff_datetime           object\n",
       "PUlocationID                int64\n",
       "DOlocationID                int64\n",
       "SR_Flag                   float64\n",
       "Affiliated_base_number     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b17e4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50e88848",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField(\"dispatching_base_num\", types.StringType(), True),\n",
    "    types.StructField(\"pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"dropOff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"PUlocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOlocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"SR_Flag\", types.StringType(), True),\n",
    "    types.StructField(\"Affiliated_base_number\", types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2e5439b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', LongType(), True), StructField('DOlocationID', LongType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd25b79",
   "metadata": {},
   "source": [
    "# Upload fhv data to spark with schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8261bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2019-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49a75737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   NULL|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   NULL|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   NULL|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   NULL|       B00021         |\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   NULL|                B00037|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   NULL|                  #N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f44ece",
   "metadata": {},
   "source": [
    "# Save fhv data as partitioned parquet files and read with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aee76b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3603bec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhv/2020/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27341cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhv/2020/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f93df40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f3f8e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   NULL|                  NULL|\n",
      "|              B01315|2019-10-05 15:13:04|2019-10-05 15:19:48|         264|          74|   NULL|                B01315|\n",
      "|              B01984|2019-10-12 17:13:00|2019-10-12 17:40:00|         264|          75|   NULL|                B01984|\n",
      "|              B00310|2019-10-15 10:55:04|2019-10-15 11:00:45|         264|         247|   NULL|                B03047|\n",
      "|              B00932|2019-10-08 06:58:42|2019-10-08 07:11:11|         264|          37|   NULL|                B00932|\n",
      "|              B01029|2019-10-10 14:45:00|2019-10-10 15:47:00|         264|         264|   NULL|                B01029|\n",
      "|              B01087|2019-10-14 18:41:24|2019-10-14 19:02:06|         261|         186|   NULL|                B01087|\n",
      "|              B03080|2019-10-05 14:49:10|2019-10-05 15:02:14|         264|          25|   NULL|                B02889|\n",
      "|              B03160|2019-10-10 12:50:00|2019-10-10 13:34:00|          77|          77|   NULL|                B02882|\n",
      "|              B02472|2019-10-16 14:12:36|2019-10-16 14:35:00|         264|         157|   NULL|                B02472|\n",
      "|              B01051|2019-10-05 22:06:46|2019-10-05 22:16:57|         264|         182|   NULL|                B01051|\n",
      "|              B02111|2019-10-08 14:58:52|2019-10-08 15:40:41|          98|          79|   NULL|                B02111|\n",
      "|              B00254|2019-10-03 20:33:11|2019-10-03 21:52:16|         246|         265|   NULL|                B02356|\n",
      "|              B00756|2019-10-16 10:58:00|2019-10-16 11:18:00|         264|         264|   NULL|                B00756|\n",
      "|              B02249|2019-10-04 19:55:49|2019-10-04 20:08:25|         264|         192|   NULL|                B02249|\n",
      "|              B03202|2019-10-13 07:39:33|2019-10-13 08:18:31|         264|         132|   NULL|                B03202|\n",
      "|              B00419|2019-10-11 08:33:12|2019-10-11 08:46:22|         182|         185|   NULL|                B00419|\n",
      "|              B02095|2019-10-09 11:16:00|2019-10-09 11:44:00|         264|         264|   NULL|                B02095|\n",
      "|              B02930|2019-10-05 22:06:15|2019-10-05 22:25:31|         264|          69|   NULL|                B02930|\n",
      "|              B01239|2019-10-07 20:08:15|2019-10-07 20:16:06|         264|          51|   NULL|                B02847|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbd68c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropOff_datetime',\n",
       " 'PUlocationID',\n",
       " 'DOlocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c11f3aa",
   "metadata": {},
   "source": [
    "# Upload created data to temporary table to use with sql:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6d548b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('fhv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d9aec",
   "metadata": {},
   "source": [
    "# Question 3: Count records on 15th of October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91da207a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 7:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|trips|\n",
      "+-----+\n",
      "|62610|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark \\\n",
    ".sql(\"\"\"\n",
    "SELECT COUNT(*) as trips\n",
    "FROM fhv\n",
    "WHERE to_date(pickup_datetime) = '2019-10-15'\n",
    "\"\"\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be06506f",
   "metadata": {},
   "source": [
    "# Question 4: The longest trip in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95e01065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 20:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------------+\n",
      "|   dropOff_datetime|    pickup_datetime|length_of_trip_in_hours|\n",
      "+-------------------+-------------------+-----------------------+\n",
      "|2091-10-11 18:30:00|2019-10-11 18:00:00|               631152.5|\n",
      "|2091-10-28 09:30:00|2019-10-28 09:00:00|               631152.5|\n",
      "|2029-11-01 00:13:00|2019-10-31 23:46:33|      87672.44083333333|\n",
      "|2027-10-01 21:45:23|2019-10-01 21:43:42|      70128.02805555555|\n",
      "|2020-10-18 00:00:00|2019-10-17 14:00:00|                 8794.0|\n",
      "|2020-10-26 21:36:00|2019-10-26 21:26:00|      8784.166666666666|\n",
      "|2019-12-30 13:02:08|2019-10-30 12:30:04|     1464.5344444444445|\n",
      "|2019-12-08 07:54:33|2019-10-25 07:04:57|     1056.8266666666666|\n",
      "|2019-12-08 07:21:11|2019-10-25 07:04:57|     1056.2705555555556|\n",
      "|2019-11-03 15:20:28|2019-10-01 13:47:17|      793.5530555555556|\n",
      "|2019-11-03 08:44:21|2019-10-01 07:21:12|      793.3858333333334|\n",
      "|2019-11-03 14:58:51|2019-10-01 13:41:00|               793.2975|\n",
      "|2019-11-03 19:43:13|2019-10-01 18:43:20|      792.9980555555555|\n",
      "|2019-11-03 19:43:04|2019-10-01 18:43:46|      792.9883333333333|\n",
      "|2019-11-03 07:58:46|2019-10-01 07:07:09|      792.8602777777778|\n",
      "|2019-11-03 15:38:07|2019-10-01 14:49:28|      792.8108333333333|\n",
      "|2019-11-03 06:23:36|2019-10-01 05:36:30|                792.785|\n",
      "|2019-11-03 15:49:05|2019-10-01 15:02:55|      792.7694444444444|\n",
      "|2019-11-03 06:53:15|2019-10-01 06:08:01|      792.7538888888889|\n",
      "|2019-11-03 07:26:04|2019-10-01 06:41:17|      792.7463888888889|\n",
      "+-------------------+-------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 20:=============================>                            (1 + 1) / 2]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark \\\n",
    ".sql(\"\"\"\n",
    "SELECT dropOff_datetime,\n",
    "pickup_datetime,\n",
    "(cast(dropOff_datetime as LONG) - cast(pickup_datetime as LONG))/3600 as length_of_trip_in_hours\n",
    "FROM fhv\n",
    "ORDER BY length_of_trip_in_hours DESC\n",
    "\"\"\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593af6b",
   "metadata": {},
   "source": [
    "# Download taxi zone lookup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51d18bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-06 08:44:03--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240306T084404Z&X-Amz-Expires=300&X-Amz-Signature=aeb6d7071ccfcf5631647765be6adc76bdad3b7a688877be964938897951ffe8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-06 08:44:04--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240306T084404Z&X-Amz-Expires=300&X-Amz-Signature=aeb6d7071ccfcf5631647765be6adc76bdad3b7a688877be964938897951ffe8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-06 08:44:04 (30.3 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb82df7",
   "metadata": {},
   "source": [
    "# Check schema and create a new one to taxi zone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a379fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edec2a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('LocationID', LongType(), True), StructField('Borough', StringType(), True), StructField('Zone', StringType(), True), StructField('service_zone', StringType(), True)])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_zones).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a48a035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_taxi_zone = types.StructType([\n",
    "            types.StructField('LocationID', types.IntegerType(), True), \n",
    "            types.StructField('Borough', types.StringType(), True), \n",
    "            types.StructField('Zone', types.StringType(), True), \n",
    "            types.StructField('service_zone', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be3a91",
   "metadata": {},
   "source": [
    "# Upload taxi zone data to spark with schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e21dde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema_taxi_zone) \\\n",
    "    .csv('taxi_zone_lookup.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16452e27",
   "metadata": {},
   "source": [
    "# Save taxi zone data as parquet and read with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "927ac659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.write.parquet('zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d823117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('zone/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a17e9",
   "metadata": {},
   "source": [
    "# Upload created data to temporary table to use with sql:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deae0c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/spark/spark-3.5.1-bin-hadoop3/python/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_zones.registerTempTable('zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94dd8f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff5338",
   "metadata": {},
   "source": [
    "# Question 6: Least frequent pickup location zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bad2a04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 17:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|frequent_count|         pickup_zone|\n",
      "+--------------+--------------------+\n",
      "|             1|         Jamaica Bay|\n",
      "|             2|Governor's Island...|\n",
      "|             5| Green-Wood Cemetery|\n",
      "|             8|       Broad Channel|\n",
      "|            14|     Highbridge Park|\n",
      "|            15|        Battery Park|\n",
      "|            23|Saint Michaels Ce...|\n",
      "|            25|Breezy Point/Fort...|\n",
      "|            26|Marine Park/Floyd...|\n",
      "|            29|        Astoria Park|\n",
      "|            39|    Inwood Hill Park|\n",
      "|            47|       Willets Point|\n",
      "|            53|Forest Park/Highl...|\n",
      "|            57|  Brooklyn Navy Yard|\n",
      "|            62|        Crotona Park|\n",
      "|            77|        Country Club|\n",
      "|            89|     Freshkills Park|\n",
      "|            98|       Prospect Park|\n",
      "|           105|     Columbia Street|\n",
      "|           110|  South Williamsburg|\n",
      "+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark \\\n",
    ".sql(\"\"\"\n",
    "SELECT COUNT(*) AS frequent_count,\n",
    "puzone.Zone as pickup_zone\n",
    "FROM fhv\n",
    "LEFT JOIN zone as puzone\n",
    "    ON fhv.PULocationID = puzone.LocationID\n",
    "LEFT JOIN zone as dozone\n",
    "    ON fhv.DOLocationID = dozone.LocationID\n",
    "GROUP BY pickup_zone\n",
    "ORDER BY frequent_count ASC\n",
    "\"\"\") \\\n",
    ".show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
